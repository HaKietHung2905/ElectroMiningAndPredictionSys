{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "aloIcj_0KzZl"
      },
      "outputs": [],
      "source": [
        "# Import packages and modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "9gHROikIKzZm"
      },
      "outputs": [],
      "source": [
        "df  = pd.read_csv(\"../Data/dataset_dk3619_preprocessed_v1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "TEzRrgirR21X",
        "outputId": "8d64321d-55a9-4d4f-a93c-bfbbc7d41973"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3323747, 44)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4-swQrHQIwV",
        "outputId": "ce568480-d107-4883-afe9-7bb8359a2ea9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0                M_MA\n",
            "1          C_CE_CF_CD\n",
            "2                 G_G\n",
            "3                Q_QA\n",
            "4                 P_P\n",
            "              ...    \n",
            "3323742           E_E\n",
            "3323743           F_F\n",
            "3323744           I_I\n",
            "3323745           H_H\n",
            "3323746           A_A\n",
            "Name: DK3619Code, Length: 3323747, dtype: object\n",
            "{'A_A': 0, 'C_CA': 1, 'C_CC': 2, 'C_CE_CF_CD': 3, 'C_CG': 4, 'C_CH': 5, 'C_CI': 6, 'C_CJ': 7, 'C_CK': 8, 'C_CL': 9, 'C_CM_CB': 10, 'D_D': 11, 'E_E': 12, 'F_F': 13, 'G_G': 14, 'H_H': 15, 'I_I': 16, 'J_JA': 17, 'J_JB_JC': 18, 'K_K': 19, 'L_L': 20, 'M_MA': 21, 'M_MB': 22, 'M_MC': 23, 'N_N': 24, 'O_O': 25, 'PR_PR': 26, 'P_P': 27, 'Q_QA': 28, 'Q_QB': 29, 'R_R': 30, 'S_S': 31}\n"
          ]
        }
      ],
      "source": [
        "print(df['DK3619Code'])\n",
        "dkcode_list = list(set(df['DK3619Code'].to_list()))\n",
        "dkcode_list.sort()\n",
        "id2dkcode = enumerate(dkcode_list)\n",
        "id2dkcode = dict(id2dkcode)\n",
        "\n",
        "dkcode2id = {}\n",
        "for i in id2dkcode.items():\n",
        "    dkcode2id[i[1]] = i[0]\n",
        "print(dict(dkcode2id))\n",
        "\n",
        "### Mapping data to numberic\n",
        "# df['DK3619Code'] = df['DK3619Code'].map(dkcode2id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cM5V7GE-KzZm"
      },
      "source": [
        "### Choose Feauture will use for Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Jxs0IoICKzZn"
      },
      "outputs": [],
      "source": [
        "columns = ['HourUTC', 'HourDK', 'hour', 'day_of_week',\n",
        "              'weekday_name', 'quarter', 'month', 'year', 'day_of_year',\n",
        "              'day_of_month', 'week_of_year', 'season', 'holiday', 'Consumption_MWh']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRZ555mIKzZn",
        "outputId": "df92bc86-1752-4026-8ffc-643b77695b7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['HourUTC', 'HourDK', 'DK3619Code', 'hour', 'day_of_week',\n",
              "       'weekday_name', 'quarter', 'month', 'year', 'day_of_year',\n",
              "       'day_of_month', 'week_of_year', 'season', 'holiday', 'DK36Code',\n",
              "       'DK36Title', 'DK19Code', 'DK19Title', 'Consumption_MWh', 'lag_24',\n",
              "       'lag_25', 'lag_26', 'lag_27', 'lag_28', 'lag_29', 'lag_30', 'lag_31',\n",
              "       'lag_32', 'lag_33', 'lag_34', 'lag_35', 'lag_36', 'lag_37', 'lag_38',\n",
              "       'lag_39', 'lag_40', 'lag_41', 'lag_42', 'lag_43', 'lag_44', 'lag_45',\n",
              "       'lag_46', 'lag_47', 'lag_48'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "okUyekmXLwn1"
      },
      "outputs": [],
      "source": [
        "# print(df['weekday_name'])\n",
        "# weekday_list = list(set(df['weekday_name'].to_list()))\n",
        "# weekday_list.sort()\n",
        "# id2day = enumerate(weekday_list)\n",
        "# id2day = dict(id2day)\n",
        "\n",
        "# day2id = {}\n",
        "# for i in id2day.items():\n",
        "#     day2id[i[1]] = i[0]\n",
        "# print(dict(day2id))\n",
        "\n",
        "### Mapping data to numberic\n",
        "# df['weekday_name'] = df['weekday_name'].map(day2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "o9TgP3b7gKa6"
      },
      "outputs": [],
      "source": [
        "weekday_mapping = {\n",
        "    'Monday': 0,\n",
        "    'Tuesday': 1,\n",
        "    'Wednesday': 2,\n",
        "    'Thursday': 3,\n",
        "    'Friday': 4,\n",
        "    'Saturday': 5,\n",
        "    'Sunday': 6\n",
        "}\n",
        "### Mapping data to numberic\n",
        "df['weekday_name'] = df['weekday_name'].map(weekday_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BWm2XBZSOAuh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "C-vvay5POZCq"
      },
      "outputs": [],
      "source": [
        "# print(df['season'])\n",
        "# season_list = list(set(df['season'].to_list()))\n",
        "# season_list.sort()\n",
        "# id2season = enumerate(season_list)\n",
        "# id2season = dict(id2season)\n",
        "\n",
        "# season2id = {}\n",
        "# for i in id2season.items():\n",
        "#     season2id[i[1]] = i[0]\n",
        "# print(dict(season2id))\n",
        "\n",
        "### Season mapping\n",
        "# df['season'] = df['season'].map(season2id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "qJUgNLfaKzZo"
      },
      "outputs": [],
      "source": [
        "\n",
        "### Season mapping\n",
        "\n",
        "seasons_mapping = {\n",
        "    'Spring': 0,\n",
        "    'Summer': 1,\n",
        "    'Autumn': 2,\n",
        "    'Winter': 3\n",
        "}\n",
        "\n",
        "df['season'] = df['season'].map(seasons_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['day_of_month'] = df['day_of_month'].astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "XI00LfRLUcPR",
        "outputId": "1f2638f2-09ae-4d29-a3c8-1a8d6521f46d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HourUTC</th>\n",
              "      <th>HourDK</th>\n",
              "      <th>DK3619Code</th>\n",
              "      <th>hour</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>weekday_name</th>\n",
              "      <th>quarter</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>day_of_year</th>\n",
              "      <th>...</th>\n",
              "      <th>lag_39</th>\n",
              "      <th>lag_40</th>\n",
              "      <th>lag_41</th>\n",
              "      <th>lag_42</th>\n",
              "      <th>lag_43</th>\n",
              "      <th>lag_44</th>\n",
              "      <th>lag_45</th>\n",
              "      <th>lag_46</th>\n",
              "      <th>lag_47</th>\n",
              "      <th>lag_48</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-06-01T23:00:00</td>\n",
              "      <td>2012-06-02 01:00:00</td>\n",
              "      <td>M_MA</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>2012</td>\n",
              "      <td>154</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012-06-01T23:00:00</td>\n",
              "      <td>2012-06-02 01:00:00</td>\n",
              "      <td>C_CE_CF_CD</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>2012</td>\n",
              "      <td>154</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012-06-02T00:00:00</td>\n",
              "      <td>2012-06-02 02:00:00</td>\n",
              "      <td>G_G</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>2012</td>\n",
              "      <td>154</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-06-02T00:00:00</td>\n",
              "      <td>2012-06-02 02:00:00</td>\n",
              "      <td>Q_QA</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>2012</td>\n",
              "      <td>154</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-06-02T00:00:00</td>\n",
              "      <td>2012-06-02 02:00:00</td>\n",
              "      <td>P_P</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>2012</td>\n",
              "      <td>154</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 44 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               HourUTC               HourDK  DK3619Code  hour  day_of_week  \\\n",
              "0  2012-06-01T23:00:00  2012-06-02 01:00:00        M_MA     1            5   \n",
              "1  2012-06-01T23:00:00  2012-06-02 01:00:00  C_CE_CF_CD     1            5   \n",
              "2  2012-06-02T00:00:00  2012-06-02 02:00:00         G_G     2            5   \n",
              "3  2012-06-02T00:00:00  2012-06-02 02:00:00        Q_QA     2            5   \n",
              "4  2012-06-02T00:00:00  2012-06-02 02:00:00         P_P     2            5   \n",
              "\n",
              "   weekday_name  quarter  month  year  day_of_year  ...  lag_39  lag_40  \\\n",
              "0             5        2      6  2012          154  ...     NaN     NaN   \n",
              "1             5        2      6  2012          154  ...     NaN     NaN   \n",
              "2             5        2      6  2012          154  ...     NaN     NaN   \n",
              "3             5        2      6  2012          154  ...     NaN     NaN   \n",
              "4             5        2      6  2012          154  ...     NaN     NaN   \n",
              "\n",
              "   lag_41  lag_42 lag_43 lag_44 lag_45 lag_46  lag_47  lag_48  \n",
              "0     NaN     NaN    NaN    NaN    NaN    NaN     NaN     NaN  \n",
              "1     NaN     NaN    NaN    NaN    NaN    NaN     NaN     NaN  \n",
              "2     NaN     NaN    NaN    NaN    NaN    NaN     NaN     NaN  \n",
              "3     NaN     NaN    NaN    NaN    NaN    NaN     NaN     NaN  \n",
              "4     NaN     NaN    NaN    NaN    NaN    NaN     NaN     NaN  \n",
              "\n",
              "[5 rows x 44 columns]"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdTOtQYEKzZp"
      },
      "source": [
        "### Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "uOy_vLB9KzZp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.plotting import lag_plot\n",
        "from pandas.plotting import autocorrelation_plot\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,GRU, Dense, Bidirectional\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.layers import TimeDistributed, Flatten, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "import os.path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "GPLXrBNpKzZq"
      },
      "outputs": [],
      "source": [
        "# Create sequences\n",
        "def create_sequences(df, seq_length):\n",
        "    sequences = []\n",
        "    labels = []\n",
        "    for i in range(len(df) - seq_length):\n",
        "        seq = df.iloc[i:i+seq_length].values\n",
        "        label = df['Consumption_MWh'].iloc[i+seq_length]\n",
        "        sequences.append(seq)\n",
        "        labels.append(label)\n",
        "    return np.array(sequences), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\danny.ha\\AppData\\Local\\Temp\\ipykernel_12100\\446129615.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_corr['HourUTC'] = pd.to_datetime(df_corr['HourUTC'])\n",
            "C:\\Users\\danny.ha\\AppData\\Local\\Temp\\ipykernel_12100\\446129615.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_corr['HourDK'] = pd.to_datetime(df_corr['HourDK'])\n"
          ]
        }
      ],
      "source": [
        "df_filter = df[df['DK3619Code'] == 'M_MA']\n",
        "df_corr = df_filter[columns]\n",
        "\n",
        "df_corr['HourUTC'] = pd.to_datetime(df_corr['HourUTC'])\n",
        "df_corr['HourDK'] = pd.to_datetime(df_corr['HourDK'])\n",
        "\n",
        "df_corr = df_corr.drop(['HourUTC', 'HourDK'], axis=1)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "scaled_df = scaler.fit_transform(df_corr[['season', 'year', 'month', 'day_of_month', 'hour', 'Consumption_MWh']])\n",
        "\n",
        "scaled_df = pd.DataFrame(scaled_df, columns=['season', 'year', 'month', 'day_of_month', 'hour', 'Consumption_MWh'])\n",
        "\n",
        "#create sequence for training\n",
        "SEQ_LENGTH = 24  # for 24 hours sequence\n",
        "sequences, labels = create_sequences(scaled_df, SEQ_LENGTH)\n",
        "\n",
        "# Split the data into training (60%), validation (20%), and test (20%) sets\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(sequences, labels, test_size=0.2, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[1.        , 0.83333333, 0.        , 0.7       , 0.56521739,\n",
              "         0.41874931],\n",
              "        [1.        , 0.83333333, 0.        , 0.7       , 0.60869565,\n",
              "         0.41349038],\n",
              "        [1.        , 0.83333333, 0.        , 0.7       , 0.65217391,\n",
              "         0.40803718],\n",
              "        ...,\n",
              "        [1.        , 0.83333333, 0.        , 0.73333333, 0.43478261,\n",
              "         0.40509322],\n",
              "        [1.        , 0.83333333, 0.        , 0.73333333, 0.47826087,\n",
              "         0.41143037],\n",
              "        [1.        , 0.83333333, 0.        , 0.73333333, 0.52173913,\n",
              "         0.41164813]],\n",
              "\n",
              "       [[1.        , 0.83333333, 0.        , 0.7       , 0.60869565,\n",
              "         0.41349038],\n",
              "        [1.        , 0.83333333, 0.        , 0.7       , 0.65217391,\n",
              "         0.40803718],\n",
              "        [1.        , 0.83333333, 0.        , 0.7       , 0.69565217,\n",
              "         0.41717204],\n",
              "        ...,\n",
              "        [1.        , 0.83333333, 0.        , 0.73333333, 0.47826087,\n",
              "         0.41143037],\n",
              "        [1.        , 0.83333333, 0.        , 0.73333333, 0.52173913,\n",
              "         0.41164813],\n",
              "        [1.        , 0.83333333, 0.        , 0.73333333, 0.56521739,\n",
              "         0.41240995]],\n",
              "\n",
              "       [[1.        , 0.83333333, 0.        , 0.7       , 0.65217391,\n",
              "         0.40803718],\n",
              "        [1.        , 0.83333333, 0.        , 0.7       , 0.69565217,\n",
              "         0.41717204],\n",
              "        [1.        , 0.83333333, 0.        , 0.7       , 0.73913043,\n",
              "         0.42498927],\n",
              "        ...,\n",
              "        [1.        , 0.83333333, 0.        , 0.73333333, 0.52173913,\n",
              "         0.41164813],\n",
              "        [1.        , 0.83333333, 0.        , 0.73333333, 0.56521739,\n",
              "         0.41240995],\n",
              "        [1.        , 0.83333333, 0.        , 0.73333333, 0.60869565,\n",
              "         0.40975682]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.33333333, 1.        , 0.45454545, 0.63333333, 0.91304348,\n",
              "         0.50929905],\n",
              "        [0.33333333, 1.        , 0.45454545, 0.63333333, 0.95652174,\n",
              "         0.50211537],\n",
              "        [0.33333333, 1.        , 0.45454545, 0.63333333, 1.        ,\n",
              "         0.50791252],\n",
              "        ...,\n",
              "        [0.33333333, 1.        , 0.45454545, 0.66666667, 0.7826087 ,\n",
              "         0.44013362],\n",
              "        [0.33333333, 1.        , 0.45454545, 0.66666667, 0.82608696,\n",
              "         0.41960236],\n",
              "        [0.33333333, 1.        , 0.45454545, 0.66666667, 0.86956522,\n",
              "         0.4072203 ]],\n",
              "\n",
              "       [[0.33333333, 1.        , 0.45454545, 0.63333333, 0.95652174,\n",
              "         0.50211537],\n",
              "        [0.33333333, 1.        , 0.45454545, 0.63333333, 1.        ,\n",
              "         0.50791252],\n",
              "        [0.33333333, 1.        , 0.45454545, 0.66666667, 0.        ,\n",
              "         0.51128088],\n",
              "        ...,\n",
              "        [0.33333333, 1.        , 0.45454545, 0.66666667, 0.82608696,\n",
              "         0.41960236],\n",
              "        [0.33333333, 1.        , 0.45454545, 0.66666667, 0.86956522,\n",
              "         0.4072203 ],\n",
              "        [0.33333333, 1.        , 0.45454545, 0.66666667, 0.91304348,\n",
              "         0.40813699]],\n",
              "\n",
              "       [[0.33333333, 1.        , 0.45454545, 0.63333333, 1.        ,\n",
              "         0.50791252],\n",
              "        [0.33333333, 1.        , 0.45454545, 0.66666667, 0.        ,\n",
              "         0.51128088],\n",
              "        [0.33333333, 1.        , 0.45454545, 0.66666667, 0.04347826,\n",
              "         0.49253964],\n",
              "        ...,\n",
              "        [0.33333333, 1.        , 0.45454545, 0.66666667, 0.86956522,\n",
              "         0.4072203 ],\n",
              "        [0.33333333, 1.        , 0.45454545, 0.66666667, 0.91304348,\n",
              "         0.40813699],\n",
              "        [0.33333333, 1.        , 0.45454545, 0.66666667, 0.95652174,\n",
              "         0.43167281]]])"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.41240995, 0.40975682, 0.40826677, ..., 0.40813699, 0.43167281,\n",
              "       0.47514127])"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[0.33333333, 0.        , 0.45454545, 0.03333333, 0.04347826,\n",
              "         0.        ],\n",
              "        [0.33333333, 0.        , 0.45454545, 0.03333333, 0.08695652,\n",
              "         0.15203586],\n",
              "        [0.33333333, 0.        , 0.45454545, 0.03333333, 0.13043478,\n",
              "         0.15577927],\n",
              "        ...,\n",
              "        [0.33333333, 0.        , 0.45454545, 0.03333333, 0.95652174,\n",
              "         0.15670099],\n",
              "        [0.33333333, 0.        , 0.45454545, 0.03333333, 1.        ,\n",
              "         0.15276802],\n",
              "        [0.33333333, 0.        , 0.45454545, 0.06666667, 0.        ,\n",
              "         0.14878711]],\n",
              "\n",
              "       [[0.33333333, 0.        , 0.45454545, 0.03333333, 0.08695652,\n",
              "         0.15203586],\n",
              "        [0.33333333, 0.        , 0.45454545, 0.03333333, 0.13043478,\n",
              "         0.15577927],\n",
              "        [0.33333333, 0.        , 0.45454545, 0.03333333, 0.17391304,\n",
              "         0.15528827],\n",
              "        ...,\n",
              "        [0.33333333, 0.        , 0.45454545, 0.03333333, 1.        ,\n",
              "         0.15276802],\n",
              "        [0.33333333, 0.        , 0.45454545, 0.06666667, 0.        ,\n",
              "         0.14878711],\n",
              "        [0.33333333, 0.        , 0.45454545, 0.06666667, 0.04347826,\n",
              "         0.14845213]],\n",
              "\n",
              "       [[0.33333333, 0.        , 0.45454545, 0.03333333, 0.13043478,\n",
              "         0.15577927],\n",
              "        [0.33333333, 0.        , 0.45454545, 0.03333333, 0.17391304,\n",
              "         0.15528827],\n",
              "        [0.33333333, 0.        , 0.45454545, 0.03333333, 0.2173913 ,\n",
              "         0.15389381],\n",
              "        ...,\n",
              "        [0.33333333, 0.        , 0.45454545, 0.06666667, 0.        ,\n",
              "         0.14878711],\n",
              "        [0.33333333, 0.        , 0.45454545, 0.06666667, 0.04347826,\n",
              "         0.14845213],\n",
              "        [0.33333333, 0.        , 0.45454545, 0.06666667, 0.08695652,\n",
              "         0.14614699]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[1.        , 0.83333333, 0.        , 0.7       , 0.43478261,\n",
              "         0.42997519],\n",
              "        [1.        , 0.83333333, 0.        , 0.7       , 0.47826087,\n",
              "         0.42503937],\n",
              "        [1.        , 0.83333333, 0.        , 0.7       , 0.52173913,\n",
              "         0.42329438],\n",
              "        ...,\n",
              "        [1.        , 0.83333333, 0.        , 0.73333333, 0.30434783,\n",
              "         0.38548899],\n",
              "        [1.        , 0.83333333, 0.        , 0.73333333, 0.34782609,\n",
              "         0.38908011],\n",
              "        [1.        , 0.83333333, 0.        , 0.73333333, 0.39130435,\n",
              "         0.39751229]],\n",
              "\n",
              "       [[1.        , 0.83333333, 0.        , 0.7       , 0.47826087,\n",
              "         0.42503937],\n",
              "        [1.        , 0.83333333, 0.        , 0.7       , 0.52173913,\n",
              "         0.42329438],\n",
              "        [1.        , 0.83333333, 0.        , 0.7       , 0.56521739,\n",
              "         0.41874931],\n",
              "        ...,\n",
              "        [1.        , 0.83333333, 0.        , 0.73333333, 0.34782609,\n",
              "         0.38908011],\n",
              "        [1.        , 0.83333333, 0.        , 0.73333333, 0.39130435,\n",
              "         0.39751229],\n",
              "        [1.        , 0.83333333, 0.        , 0.73333333, 0.43478261,\n",
              "         0.40509322]],\n",
              "\n",
              "       [[1.        , 0.83333333, 0.        , 0.7       , 0.52173913,\n",
              "         0.42329438],\n",
              "        [1.        , 0.83333333, 0.        , 0.7       , 0.56521739,\n",
              "         0.41874931],\n",
              "        [1.        , 0.83333333, 0.        , 0.7       , 0.60869565,\n",
              "         0.41349038],\n",
              "        ...,\n",
              "        [1.        , 0.83333333, 0.        , 0.73333333, 0.39130435,\n",
              "         0.39751229],\n",
              "        [1.        , 0.83333333, 0.        , 0.73333333, 0.43478261,\n",
              "         0.40509322],\n",
              "        [1.        , 0.83333333, 0.        , 0.73333333, 0.47826087,\n",
              "         0.41143037]]])"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPbR6VDRVh02",
        "outputId": "1a173917-3df3-45eb-99fb-623b860d27d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training LSTM model with DKCode:  A_A\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\danny.ha\\AppData\\Local\\Temp\\ipykernel_12100\\4227678017.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_corr['HourUTC'] = pd.to_datetime(df_corr['HourUTC'])\n",
            "C:\\Users\\danny.ha\\AppData\\Local\\Temp\\ipykernel_12100\\4227678017.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_corr['HourDK'] = pd.to_datetime(df_corr['HourDK'])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4226/4226 [==============================] - 108s 24ms/step - loss: 0.0025 - val_loss: 0.0011 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "4226/4226 [==============================] - 107s 25ms/step - loss: 8.2480e-04 - val_loss: 4.5503e-04 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "4226/4226 [==============================] - 95s 22ms/step - loss: 6.1472e-04 - val_loss: 2.8966e-04 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "1378/4226 [========>.....................] - ETA: 59s - loss: 5.4511e-04"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[70], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Model Training\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../Checkpoints/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_LSTMmodel.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     50\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../Checkpoints/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_LSTMmodel.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32md:\\Annaconda\\envs\\env_3_8\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32md:\\Annaconda\\envs\\env_3_8\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#all_dkcode_trainings\n",
        "if not os.path.exists(\"../Checkpoints/\"):\n",
        "    os.makedirs(\"../Checkpoints/\")\n",
        "\n",
        "for i in dkcode_list:\n",
        "    if os.path.exists(\"../Checkpoints/\" + i + \"_LSTMmodel.h5\"):\n",
        "        continue\n",
        "    print('Training LSTM model with DKCode: ', i)\n",
        "    df_filter = df[df['DK3619Code'] == i]\n",
        "    df_corr = df_filter[columns]\n",
        "\n",
        "    df_corr['HourUTC'] = pd.to_datetime(df_corr['HourUTC'])\n",
        "    df_corr['HourDK'] = pd.to_datetime(df_corr['HourDK'])\n",
        "\n",
        "    df_corr = df_corr.drop(['HourUTC', 'HourDK'], axis=1)\n",
        "\n",
        "    # Normalize the data\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled_df = scaler.fit_transform(df_corr[['season', 'year', 'month', 'hour', 'Consumption_MWh']])\n",
        "\n",
        "    scaled_df = pd.DataFrame(scaled_df, columns=['season', 'year', 'month', 'hour', 'Consumption_MWh'])\n",
        "\n",
        "    #create sequence for training\n",
        "    SEQ_LENGTH = 24  # for 24 hours sequence\n",
        "    sequences, labels = create_sequences(scaled_df, SEQ_LENGTH)\n",
        "\n",
        "    # Split the data into training (60%), validation (20%), and test (20%) sets\n",
        "    # Train-Test Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(sequences, labels, test_size=0.2, shuffle=False)\n",
        "\n",
        "    #LSTM modeling\n",
        "    model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(SEQ_LENGTH, X_train.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    LSTM(50),\n",
        "    Dropout(0.2),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    # Callbacks for early stopping and learning rate reduction\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
        "\n",
        "    # Model Training\n",
        "    history = model.fit(X_train, y_train, epochs=10, batch_size=16, validation_split=0.2, callbacks=[early_stopping, reduce_lr])\n",
        "\n",
        "    model.save(\"../Checkpoints/\" + i + \"_LSTMmodel.h5\")\n",
        "    model = tf.keras.models.load_model(\"../Checkpoints/\" + i + \"_LSTMmodel.h5\")\n",
        "\n",
        "\n",
        "    # Model Evaluation\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    r2 = r2_score(y_test, predictions)\n",
        "    mae = mean_absolute_error(y_test, predictions)\n",
        "    mse = mean_squared_error(y_test, predictions)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    print(f'RÂ² Score: {r2}')\n",
        "    print(f'Mean Absolute Error (MAE): {mae}')\n",
        "    print(f'Mean Squared Error (MSE): {mse}')\n",
        "    print(f'Root Mean Squared Error (RMSE): {rmse}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EO_GVguLW2Eq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env_3_11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
