{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "aloIcj_0KzZl"
      },
      "outputs": [],
      "source": [
        "# Import packages and modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "9gHROikIKzZm"
      },
      "outputs": [],
      "source": [
        "df  = pd.read_csv(\"../Data/dataset_dk3619_preprocessed_v1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "TEzRrgirR21X",
        "outputId": "8d0fccb8-38b3-4319-d602-a4741fcea1d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3323747, 43)"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4-swQrHQIwV",
        "outputId": "67583145-dccf-47ed-fb36-663d054feb86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0                 A_A\n",
            "1                C_CA\n",
            "2                C_CC\n",
            "3          C_CE_CF_CD\n",
            "4                C_CG\n",
            "              ...    \n",
            "3323742          Q_QB\n",
            "3323743           R_R\n",
            "3323744           S_S\n",
            "3323745    C_CE_CF_CD\n",
            "3323746          M_MA\n",
            "Name: DK3619Code, Length: 3323747, dtype: object\n",
            "{'A_A': 0, 'C_CA': 1, 'C_CC': 2, 'C_CE_CF_CD': 3, 'C_CG': 4, 'C_CH': 5, 'C_CI': 6, 'C_CJ': 7, 'C_CK': 8, 'C_CL': 9, 'C_CM_CB': 10, 'D_D': 11, 'E_E': 12, 'F_F': 13, 'G_G': 14, 'H_H': 15, 'I_I': 16, 'J_JA': 17, 'J_JB_JC': 18, 'K_K': 19, 'L_L': 20, 'M_MA': 21, 'M_MB': 22, 'M_MC': 23, 'N_N': 24, 'O_O': 25, 'PR_PR': 26, 'P_P': 27, 'Q_QA': 28, 'Q_QB': 29, 'R_R': 30, 'S_S': 31}\n"
          ]
        }
      ],
      "source": [
        "print(df['DK3619Code'])\n",
        "dkcode_list = list(set(df['DK3619Code'].to_list()))\n",
        "dkcode_list.sort()\n",
        "id2dkcode = enumerate(dkcode_list)\n",
        "id2dkcode = dict(id2dkcode)\n",
        "\n",
        "dkcode2id = {}\n",
        "for i in id2dkcode.items():\n",
        "    dkcode2id[i[1]] = i[0]\n",
        "\n",
        "\n",
        "print(dict(dkcode2id))\n",
        "\n",
        "### Mapping data to numberic\n",
        "# df['DK3619Code'] = df['DK3619Code'].map(dkcode2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Season mapping \n",
        "\n",
        "seasons_mapping = {\n",
        "    'Spring': 0,\n",
        "    'Summer': 1,\n",
        "    'Autumn': 2,\n",
        "    'Winter': 3\n",
        "}\n",
        "\n",
        "df['season'] = df['season'].map(seasons_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export the dkcode_list to a CSV file\n",
        "dkcode_df = pd.DataFrame(dkcode_list, columns=['DK3619Code'])\n",
        "dkcode_df.to_csv('dkcode_list.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cM5V7GE-KzZm"
      },
      "source": [
        "### Choose Feauture will use for Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "Jxs0IoICKzZn"
      },
      "outputs": [],
      "source": [
        "columns = ['HourUTC', 'HourDK', 'hour', 'day_of_week', 'month', 'year', 'day_of_year', 'day_of_month', 'season', 'holiday', 'lag_24', 'Consumption_MWh']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "N6srmMDKzRE8",
        "outputId": "589b5937-54ff-48e6-d7a0-14908c2f7175"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HourUTC</th>\n",
              "      <th>HourDK</th>\n",
              "      <th>hour</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>month</th>\n",
              "      <th>year</th>\n",
              "      <th>day_of_year</th>\n",
              "      <th>day_of_month</th>\n",
              "      <th>season</th>\n",
              "      <th>holiday</th>\n",
              "      <th>lag_24</th>\n",
              "      <th>Consumption_MWh</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2024-06-21T21:00:00</td>\n",
              "      <td>2024-06-21 23:00:00</td>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>2024</td>\n",
              "      <td>173</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>145.018660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2024-06-21T21:00:00</td>\n",
              "      <td>2024-06-21 23:00:00</td>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>2024</td>\n",
              "      <td>173</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>189.913841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2024-06-21T21:00:00</td>\n",
              "      <td>2024-06-21 23:00:00</td>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>2024</td>\n",
              "      <td>173</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>27.199219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2024-06-21T21:00:00</td>\n",
              "      <td>2024-06-21 23:00:00</td>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>2024</td>\n",
              "      <td>173</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>174.295128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2024-06-21T21:00:00</td>\n",
              "      <td>2024-06-21 23:00:00</td>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>2024</td>\n",
              "      <td>173</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>105.906493</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               HourUTC               HourDK  hour  day_of_week  month  year  \\\n",
              "0  2024-06-21T21:00:00  2024-06-21 23:00:00    23            4      6  2024   \n",
              "1  2024-06-21T21:00:00  2024-06-21 23:00:00    23            4      6  2024   \n",
              "2  2024-06-21T21:00:00  2024-06-21 23:00:00    23            4      6  2024   \n",
              "3  2024-06-21T21:00:00  2024-06-21 23:00:00    23            4      6  2024   \n",
              "4  2024-06-21T21:00:00  2024-06-21 23:00:00    23            4      6  2024   \n",
              "\n",
              "   day_of_year  day_of_month  season  holiday  lag_24  Consumption_MWh  \n",
              "0          173            21       1        0     NaN       145.018660  \n",
              "1          173            21       1        0     NaN       189.913841  \n",
              "2          173            21       1        0     NaN        27.199219  \n",
              "3          173            21       1        0     NaN       174.295128  \n",
              "4          173            21       1        0     NaN       105.906493  "
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_corr = df[columns]\n",
        "df_corr.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/82/s1cgdl3s5hn10rsmff2gt35r0000gn/T/ipykernel_5765/3026962626.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_corr['holiday'] = df_corr['holiday'].apply(lambda x: 0 if x == 0 else 1)\n"
          ]
        }
      ],
      "source": [
        "# Convert holiday to binary indicator\n",
        "df_corr['holiday'] = df_corr['holiday'].apply(lambda x: 0 if x == 0 else 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdTOtQYEKzZp"
      },
      "source": [
        "### Split data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "uOy_vLB9KzZp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.plotting import lag_plot\n",
        "from pandas.plotting import autocorrelation_plot\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,GRU, Dense, Bidirectional\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "from tensorflow.keras.layers import TimeDistributed, Flatten, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "import os.path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "GPLXrBNpKzZq"
      },
      "outputs": [],
      "source": [
        "# Create sequences\n",
        "def create_sequences(df, seq_length):\n",
        "    sequences = []\n",
        "    labels = []\n",
        "    for i in range(len(df) - seq_length):\n",
        "        seq = df.iloc[i:i+seq_length].values\n",
        "        label = df['Consumption_MWh'].iloc[i+seq_length]\n",
        "        sequences.append(seq)\n",
        "        labels.append(label)\n",
        "    return np.array(sequences), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPbR6VDRVh02",
        "outputId": "c3d9f350-1f8c-462e-c422-3f29e9282b04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training LSTM model with DKCode:  A_A\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/82/s1cgdl3s5hn10rsmff2gt35r0000gn/T/ipykernel_5765/3424048985.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_corr['lag_24'] = df_corr['lag_24'].fillna(0)\n",
            "/var/folders/82/s1cgdl3s5hn10rsmff2gt35r0000gn/T/ipykernel_5765/3424048985.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_corr['HourUTC'] = pd.to_datetime(df_corr['HourUTC'])\n",
            "/var/folders/82/s1cgdl3s5hn10rsmff2gt35r0000gn/T/ipykernel_5765/3424048985.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_corr['HourDK'] = pd.to_datetime(df_corr['HourDK'])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4226/4226 [==============================] - 29s 7ms/step - loss: 0.0041 - val_loss: 0.0037 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "4226/4226 [==============================] - 27s 6ms/step - loss: 9.3134e-04 - val_loss: 0.0016 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "4226/4226 [==============================] - 27s 6ms/step - loss: 4.7211e-04 - val_loss: 0.0010 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "4226/4226 [==============================] - 32s 7ms/step - loss: 3.7326e-04 - val_loss: 0.0011 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "4226/4226 [==============================] - 30s 7ms/step - loss: 3.3834e-04 - val_loss: 2.8834e-04 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "4226/4226 [==============================] - 30s 7ms/step - loss: 3.1259e-04 - val_loss: 6.1030e-04 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "4226/4226 [==============================] - 30s 7ms/step - loss: 2.9754e-04 - val_loss: 4.1516e-04 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "4226/4226 [==============================] - 30s 7ms/step - loss: 2.8841e-04 - val_loss: 9.7403e-04 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "4226/4226 [==============================] - 31s 7ms/step - loss: 2.7083e-04 - val_loss: 6.9618e-04 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "4226/4226 [==============================] - 31s 7ms/step - loss: 2.6427e-04 - val_loss: 4.3657e-04 - lr: 0.0010\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/hung/anaconda3/envs/Env3_8/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "661/661 [==============================] - 2s 2ms/step\n",
            "R² Score: 0.7862740214383727\n",
            "Mean Absolute Error (MAE): 0.021565856973272644\n",
            "Mean Squared Error (MSE): 0.0007949731518635814\n",
            "Root Mean Squared Error (RMSE): 0.02819526825308781\n",
            "Training LSTM model with DKCode:  C_CG\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/82/s1cgdl3s5hn10rsmff2gt35r0000gn/T/ipykernel_5765/3424048985.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_corr['lag_24'] = df_corr['lag_24'].fillna(0)\n",
            "/var/folders/82/s1cgdl3s5hn10rsmff2gt35r0000gn/T/ipykernel_5765/3424048985.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_corr['HourUTC'] = pd.to_datetime(df_corr['HourUTC'])\n",
            "/var/folders/82/s1cgdl3s5hn10rsmff2gt35r0000gn/T/ipykernel_5765/3424048985.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_corr['HourDK'] = pd.to_datetime(df_corr['HourDK'])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4226/4226 [==============================] - 31s 7ms/step - loss: 0.0049 - val_loss: 0.0010 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "4226/4226 [==============================] - 31s 7ms/step - loss: 0.0012 - val_loss: 4.5960e-04 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "4226/4226 [==============================] - 29s 7ms/step - loss: 6.5911e-04 - val_loss: 0.0018 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "4226/4226 [==============================] - 29s 7ms/step - loss: 5.3830e-04 - val_loss: 2.9529e-04 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "4226/4226 [==============================] - 29s 7ms/step - loss: 5.0371e-04 - val_loss: 3.7102e-04 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "4226/4226 [==============================] - 30s 7ms/step - loss: 4.7655e-04 - val_loss: 2.9071e-04 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "4226/4226 [==============================] - 28s 7ms/step - loss: 4.5261e-04 - val_loss: 3.3005e-04 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "4226/4226 [==============================] - 30s 7ms/step - loss: 4.3756e-04 - val_loss: 2.2427e-04 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "4226/4226 [==============================] - 29s 7ms/step - loss: 4.2789e-04 - val_loss: 2.7257e-04 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "4226/4226 [==============================] - 29s 7ms/step - loss: 3.7604e-04 - val_loss: 1.9861e-04 - lr: 5.0000e-04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/hung/anaconda3/envs/Env3_8/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "661/661 [==============================] - 2s 2ms/step\n",
            "R² Score: 0.9656581198408357\n",
            "Mean Absolute Error (MAE): 0.013375795143041186\n",
            "Mean Squared Error (MSE): 0.00028206572149232245\n",
            "Root Mean Squared Error (RMSE): 0.01679481233870514\n",
            "Training LSTM model with DKCode:  C_CH\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/82/s1cgdl3s5hn10rsmff2gt35r0000gn/T/ipykernel_5765/3424048985.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_corr['lag_24'] = df_corr['lag_24'].fillna(0)\n",
            "/var/folders/82/s1cgdl3s5hn10rsmff2gt35r0000gn/T/ipykernel_5765/3424048985.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_corr['HourUTC'] = pd.to_datetime(df_corr['HourUTC'])\n",
            "/var/folders/82/s1cgdl3s5hn10rsmff2gt35r0000gn/T/ipykernel_5765/3424048985.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_corr['HourDK'] = pd.to_datetime(df_corr['HourDK'])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "4226/4226 [==============================] - 31s 7ms/step - loss: 0.0052 - val_loss: 0.0014 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "1568/4226 [==========>...................] - ETA: 19s - loss: 0.0020"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[96], line 54\u001b[0m\n\u001b[1;32m     51\u001b[0m reduce_lr \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Model Training\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../Checkpoints/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_LSTMmodel.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../Checkpoints/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_LSTMmodel.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/envs/Env3_8/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/anaconda3/envs/Env3_8/lib/python3.8/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m~/anaconda3/envs/Env3_8/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/anaconda3/envs/Env3_8/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/anaconda3/envs/Env3_8/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[0;32m~/anaconda3/envs/Env3_8/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/Env3_8/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_call_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[0;32m~/anaconda3/envs/Env3_8/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1690\u001b[0m, in \u001b[0;36mConcreteFunction._build_call_outputs\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m   1687\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;66;03m# Replace outputs with results, skipping over any 'None' values.\u001b[39;00m\n\u001b[0;32m-> 1690\u001b[0m outputs_list \u001b[38;5;241m=\u001b[39m \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1691\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1692\u001b[0m j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(outputs_list):\n",
            "File \u001b[0;32m~/anaconda3/envs/Env3_8/lib/python3.8/site-packages/tensorflow/python/util/nest.py:290\u001b[0m, in \u001b[0;36mflatten\u001b[0;34m(structure, expand_composites)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.flatten\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflatten\u001b[39m(structure, expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    196\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a flat list from a given structure.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m    TypeError: The nest is or contains a dict with non-sortable keys.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m    289\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m nest_util\u001b[38;5;241m.\u001b[39mflatten(\n\u001b[0;32m--> 290\u001b[0m       \u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCORE\u001b[49m, structure, expand_composites\n\u001b[1;32m    291\u001b[0m   )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#all_dkcode_trainings\n",
        "if not os.path.exists(\"../Checkpoints/\"):\n",
        "    os.makedirs(\"../Checkpoints/\")\n",
        "\n",
        "for i in dkcode_list:\n",
        "    if os.path.exists(\"../Checkpoints/\" + i + \"_LSTMmodel.h5\"):\n",
        "        continue\n",
        "    print('Training LSTM model with DKCode: ', i)\n",
        "    df_filter = df[df['DK3619Code'] == i]\n",
        "    df_corr = df_filter[columns]\n",
        "    df_corr['lag_24'] = df_corr['lag_24'].fillna(0)\n",
        "\n",
        "    df_corr['HourUTC'] = pd.to_datetime(df_corr['HourUTC'])\n",
        "    df_corr['HourDK'] = pd.to_datetime(df_corr['HourDK'])\n",
        "\n",
        "    df_corr = df_corr.drop(['HourUTC', 'HourDK'], axis=1)\n",
        "\n",
        "    # Normalize the data\n",
        "    scaler = MinMaxScaler()\n",
        "    \n",
        "    #scaled_df = scaler.fit_transform(df_corr[['hour', 'day_of_week', 'month', 'year', 'day_of_year', 'day_of_month', 'season', 'holiday', 'lag_24', 'Consumption_MWh']])\n",
        "\n",
        "    #scaled_df = pd.DataFrame(scaled_df, columns=['hour', 'day_of_week', 'month', 'year', 'day_of_year', 'day_of_month', 'season', 'holiday', 'lag_24', 'Consumption_MWh'])\n",
        "\n",
        "    scaled_df = scaler.fit_transform(df_corr[['hour', 'day_of_week', 'month', 'year', 'day_of_year', 'day_of_month', 'season', 'holiday', 'Consumption_MWh']])\n",
        "\n",
        "    scaled_df = pd.DataFrame(scaled_df, columns=['hour', 'day_of_week', 'month', 'year', 'day_of_year', 'day_of_month', 'season', 'holiday', 'Consumption_MWh'])\n",
        "    \n",
        "    #create sequence for training\n",
        "    SEQ_LENGTH = 24  # for 24 hours sequence\n",
        "    sequences, labels = create_sequences(scaled_df, SEQ_LENGTH)\n",
        "\n",
        "    # Split the data into training (60%), validation (20%), and test (20%) sets\n",
        "    # Train-Test Split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(sequences, labels, test_size=0.2, shuffle=False)\n",
        "\n",
        "    #LSTM modeling\n",
        "    #SEQ_LENGTH=24 and  X_train.shape[2] = 6\n",
        "    model = Sequential([\n",
        "    LSTM(50, return_sequences=True, input_shape=(SEQ_LENGTH, X_train.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    LSTM(50),\n",
        "    Dropout(0.2),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    # Callbacks for early stopping and learning rate reduction\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
        "\n",
        "    # Model Training\n",
        "    history = model.fit(X_train, y_train, epochs=10, batch_size=16, validation_split=0.2, callbacks=[early_stopping, reduce_lr])\n",
        "\n",
        "    model.save(\"../Checkpoints/\" + i + \"_LSTMmodel.h5\")\n",
        "    model = tf.keras.models.load_model(\"../Checkpoints/\" + i + \"_LSTMmodel.h5\")\n",
        "\n",
        "\n",
        "    # Model Evaluation\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    r2 = r2_score(y_test, predictions)\n",
        "    mae = mean_absolute_error(y_test, predictions)\n",
        "    mse = mean_squared_error(y_test, predictions)\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    print(f'R² Score: {r2}')\n",
        "    print(f'Mean Absolute Error (MAE): {mae}')\n",
        "    print(f'Mean Squared Error (MSE): {mse}')\n",
        "    print(f'Root Mean Squared Error (RMSE): {rmse}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "EO_GVguLW2Eq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
